{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from statistics import mean\n",
    "from query_processing.process_query import process_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_queries(filename):\n",
    "    \"\"\" Load test queries\"\"\"\n",
    "    queries = {}\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            query_id, query_text = line.strip().split('\\t')\n",
    "            queries[query_id] = query_text\n",
    "    return queries\n",
    "\n",
    "queries = load_queries('../data/test_queries/msmarco-test2020-queries.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_qrels(filename):\n",
    "    \"\"\" Load expected relevances\"\"\"\n",
    "    qrels = {}\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            query_id, _, doc_id, relevance = line.strip().split()\n",
    "            if query_id not in qrels:\n",
    "                qrels[query_id] = {}\n",
    "            qrels[query_id][doc_id] = int(relevance)\n",
    "    return qrels\n",
    "\n",
    "qrels = load_qrels('../data/test_queries/2020qrels-pass.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the inverted index\n",
      "Inverted index loaded in 115.75539922714233 s\n",
      "Loading lexicon\n",
      "Lexicon loaded in 0.03753232955932617 s\n",
      "Loading document index\n",
      "Document index loaded in 5.401638746261597 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from input_output.index_io import load_document_index, load_inverted_index_binary, load_lexicon\n",
    "\n",
    "# Load inverted index, lexicon and document index\n",
    "inverted_index_start = time.time()\n",
    "print(\"Loading the inverted index\")\n",
    "inverted_index = load_inverted_index_binary('../data/inverted_index_8841823.bin')\n",
    "print(f\"Inverted index loaded in {time.time() - inverted_index_start} s\")\n",
    "total_docs = len(inverted_index)  # Adjust this if needed\n",
    "\n",
    "lexicon_start = time.time()\n",
    "print(\"Loading lexicon\")\n",
    "lexicon = load_lexicon('../data/lexicon.txt')\n",
    "print(f\"Lexicon loaded in {time.time() - lexicon_start} s\")\n",
    "\n",
    "document_index_start = time.time()\n",
    "print(\"Loading document index\")\n",
    "document_index = load_document_index(\"../data/document_index.txt\")\n",
    "print(f\"Document index loaded in {time.time() - document_index_start} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 nDCG tfidf :  0.11912212034693231\n",
      "Time elapsed :  66.19834518432617\n",
      "Nb of queries :  54\n",
      "Average time for each query :  1.2258952811912254\n",
      "10 nDCG tfidf :  0.1080524083016866\n",
      "Time elapsed :  66.25589299201965\n",
      "Nb of queries :  54\n",
      "Average time for each query :  1.2269609813336972\n",
      "2 nDCG bm25 :  0.18249851524083632\n",
      "Time elapsed :  108.04627966880798\n",
      "Nb of queries :  54\n",
      "Average time for each query :  2.0008570309038514\n",
      "10 nDCG bm25 :  0.16130841665728948\n",
      "Time elapsed :  105.69976377487183\n",
      "Nb of queries :  54\n",
      "Average time for each query :  1.9574030328679968\n"
     ]
    }
   ],
   "source": [
    "ndcg_list = []\n",
    "# Process all test queries and compute nDCG for TF-IDF and BM25\n",
    "for ranking in [\"tfidf\",\"bm25\"]:\n",
    "    for user_type in [2,10]:\n",
    "        nb_queries = 0\n",
    "        elapsed_time = 0\n",
    "        ndcg = []\n",
    "        for qid, query in queries.items():\n",
    "            if qid not in qrels:\n",
    "                continue\n",
    "            k = len(qrels[qid])\n",
    "            querying_start = time.time()\n",
    "            # Evaluation is made for 20 documents ranking\n",
    "            results = process_query(query, inverted_index, lexicon, document_index, total_docs, ranking)[:20]\n",
    "            elapsed_time += time.time() - querying_start\n",
    "            nb_queries += 1\n",
    "            results = {docid for docid,_ in results}\n",
    "\n",
    "            # Map resulted docs with their expected relevance\n",
    "            weighted_assessed_run = []\n",
    "            for docid in results:\n",
    "                if docid in qrels[qid]:\n",
    "                    weighted_assessed_run.append(qrels[qid][docid])\n",
    "                else:\n",
    "                    weighted_assessed_run.append(0)\n",
    "\n",
    "            if len(weighted_assessed_run) == 0 :\n",
    "                ndcg.append(0)\n",
    "                continue\n",
    "\n",
    "            # Compute DCG\n",
    "            dcg = weighted_assessed_run[0]\n",
    "            count = 1\n",
    "            for weight in weighted_assessed_run[1:]:\n",
    "                if user_type == 2:\n",
    "                    dcg += weight / math.log2(count + 1)\n",
    "                else:\n",
    "                    dcg += weight / math.log10(count + 1)\n",
    "                count += 1\n",
    "\n",
    "            # Compute IDCG\n",
    "            expected_results = list(qrels[qid].values())\n",
    "            weighted_assessed_ideal_run = sorted(expected_results)[20:]\n",
    "            idcg = weighted_assessed_ideal_run[0]\n",
    "            count = 1\n",
    "            for weight in weighted_assessed_ideal_run[1:]:\n",
    "                if user_type == 2:\n",
    "                    idcg += weight / math.log2(count + 1)\n",
    "                else:\n",
    "                    idcg += weight / math.log10(count + 1)\n",
    "                count += 1\n",
    "\n",
    "            ndcg.append(dcg/idcg)\n",
    "            \n",
    "        ndcg_list.append(mean(ndcg))\n",
    "        print(str(user_type) + \" nDCG \" + ranking + \" : \",mean(ndcg))\n",
    "        print(\"Time elapsed : \",elapsed_time)\n",
    "        print(\"Nb of queries : \",nb_queries)\n",
    "        print(\"Average time for each query : \",elapsed_time/nb_queries)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MIRCV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
