{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_queries(filename):\n",
    "    \"\"\" Load test queries\"\"\"\n",
    "    queries = {}\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            query_id, query_text = line.strip().split('\\t')\n",
    "            queries[query_id] = query_text\n",
    "    return queries\n",
    "\n",
    "queries = load_queries('../data/test_queries/msmarco-test2020-queries.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_qrels(filename):\n",
    "    \"\"\" Load expected relevances\"\"\"\n",
    "    qrels = {}\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            query_id, _, doc_id, relevance = line.strip().split()\n",
    "            if query_id not in qrels:\n",
    "                qrels[query_id] = {}\n",
    "            qrels[query_id][doc_id] = int(relevance)\n",
    "    return qrels\n",
    "\n",
    "qrels = load_qrels('../data/test_queries/2020qrels-pass.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the inverted index\n",
      "Inverted index loaded in 113.71572971343994 s\n",
      "Loading lexicon\n",
      "Lexicon loaded in 0.12911105155944824 s\n",
      "Loading document index\n",
      "Document index loaded in 7.133630990982056 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from input_output.index_io import load_document_index, load_inverted_index_binary, load_lexicon\n",
    "\n",
    "# Load inverted index, lexicon and document index\n",
    "inverted_index_start = time.time()\n",
    "print(\"Loading the inverted index\")\n",
    "inverted_index = load_inverted_index_binary('../data/inverted_index_8841823.bin')\n",
    "print(f\"Inverted index loaded in {time.time() - inverted_index_start} s\")\n",
    "total_docs = len(inverted_index)  # Adjust this if needed\n",
    "\n",
    "lexicon_start = time.time()\n",
    "print(\"Loading lexicon\")\n",
    "lexicon = load_lexicon('../data/lexicon.txt')\n",
    "print(f\"Lexicon loaded in {time.time() - lexicon_start} s\")\n",
    "\n",
    "document_index_start = time.time()\n",
    "print(\"Loading document index\")\n",
    "document_index = load_document_index(\"../data/document_index.txt\")\n",
    "print(f\"Document index loaded in {time.time() - document_index_start} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDCG :  0.12118458706471585\n",
      "Time elapsed :  70.58766388893127\n",
      "Nb of queries :  54\n",
      "Average time for each query :  1.3071789609061346\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from statistics import mean\n",
    "from query_processing.process_query import process_query\n",
    "\n",
    "# Process all test queries and compute nDCG for TFIDF\n",
    "ndcg = []\n",
    "nb_queries = 0\n",
    "elapsed_time = 0\n",
    "for qid, query in queries.items():\n",
    "    if qid not in qrels:\n",
    "        continue\n",
    "    k = len(qrels[qid])\n",
    "    querying_start = time.time()\n",
    "    # Evaluation is made for 20 documents ranking in this case\n",
    "    results = process_query(query, inverted_index, lexicon, document_index, total_docs, ranking='tfidf')[:20]\n",
    "    elapsed_time += time.time() - querying_start\n",
    "    nb_queries += 1\n",
    "    results = {docid for docid,_ in results}\n",
    "    weighted_assessed_run = []\n",
    "    for docid in results:\n",
    "        if docid in qrels[qid]:\n",
    "            weighted_assessed_run.append(qrels[qid][docid])\n",
    "        else:\n",
    "            weighted_assessed_run.append(0)\n",
    "    if len(weighted_assessed_run) == 0 :\n",
    "        ndcg.append(0)\n",
    "        continue\n",
    "\n",
    "    dcg = weighted_assessed_run[0]\n",
    "    count = 1\n",
    "    for weight in weighted_assessed_run[1:]:\n",
    "        dcg += weight / math.log2(count +1) \n",
    "        count += 1\n",
    "\n",
    "    expected_results = list(qrels[qid].values())\n",
    "    weighted_assessed_ideal_run = sorted(expected_results)[20:]\n",
    "    idcg = weighted_assessed_ideal_run[0]\n",
    "    count = 1\n",
    "    for weight in weighted_assessed_ideal_run[1:]:\n",
    "        idcg += weight / math.log2(count + 1) \n",
    "        count += 1\n",
    "\n",
    "    ndcg.append(dcg/idcg)\n",
    "\n",
    "print(\"nDCG : \",mean(ndcg))\n",
    "print(\"Time elapsed : \",elapsed_time)\n",
    "print(\"Nb of queries : \",nb_queries)\n",
    "print(\"Average time for each query : \",elapsed_time/nb_queries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDCG :  0.1872832393372296\n",
      "Time elapsed :  103.18017578125\n",
      "Nb of queries :  54\n",
      "Average time for each query :  1.9107439959490742\n"
     ]
    }
   ],
   "source": [
    "ndcg = []\n",
    "nb_queries = 0\n",
    "elapsed_time = 0\n",
    "\n",
    "# Process all test queries and compute nDCG for BM25\n",
    "for qid, query in queries.items():\n",
    "    if qid not in qrels:\n",
    "        continue\n",
    "    k = len(qrels[qid])\n",
    "    querying_start = time.time()\n",
    "    # Evaluation is made for 20 documents ranking and BM25 in this case\n",
    "    results = process_query(query, inverted_index, lexicon, document_index, total_docs, ranking='bm25')[:20]\n",
    "    elapsed_time += time.time() - querying_start\n",
    "    nb_queries += 1\n",
    "    results = {docid for docid,_ in results}\n",
    "    weighted_assessed_run = []\n",
    "    for docid in results:\n",
    "        if docid in qrels[qid]:\n",
    "            weighted_assessed_run.append(qrels[qid][docid])\n",
    "        else:\n",
    "            weighted_assessed_run.append(0)\n",
    "    if len(weighted_assessed_run) == 0 :\n",
    "        ndcg.append(0)\n",
    "        continue\n",
    "\n",
    "    dcg = weighted_assessed_run[0]\n",
    "    count = 1\n",
    "    for weight in weighted_assessed_run[1:]:\n",
    "        dcg += weight / math.log2(count +1) \n",
    "        count += 1\n",
    "\n",
    "    expected_results = list(qrels[qid].values())\n",
    "    weighted_assessed_ideal_run = sorted(expected_results)[20:]\n",
    "    idcg = weighted_assessed_ideal_run[0]\n",
    "    count = 1\n",
    "    for weight in weighted_assessed_ideal_run[1:]:\n",
    "        idcg += weight / math.log2(count + 1) \n",
    "        count += 1\n",
    "\n",
    "    ndcg.append(dcg/idcg)\n",
    "\n",
    "print(\"nDCG : \",mean(ndcg))\n",
    "print(\"Time elapsed : \",elapsed_time)\n",
    "print(\"Nb of queries : \",nb_queries)\n",
    "print(\"Average time for each query : \",elapsed_time/nb_queries)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MIRCV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
